# Jedha_Full_Stack_HPP_Prediction ( En construction ceci n'est pas la version finale )

ğŸŒŸ **PrÃ©diction d'HÃ©morragie du Post-Partum SÃ©vÃ¨re (HPP)**

ğŸš€ **Projet de Machine Learning pour la MaternitÃ© de Bourgogne**  
ğŸ’ª **CrÃ©ateur : Thibaut Modrin**

## ğŸŒ Contexte
Ce projet est nÃ© d'une collaboration avec un statisticien travaillant Ã  la maternitÃ© de Bourgogne, responsable de la compilation annuelle des donnÃ©es obstÃ©tricales rÃ©gionales. AprÃ¨s avoir analysÃ© le rapport annuel, l'HPP sÃ©vÃ¨re est apparue comme une prÃ©occupation majeure pour la maternitÃ©, justifiant la crÃ©ation d'un modÃ¨le prÃ©dictif basÃ© sur des donnÃ©es disponibles avant l'accouchement.

## ğŸ¯ Objectif
L'objectif principal est de prÃ©dire la survenue d'une HPP sÃ©vÃ¨re dÃ¨s l'arrivÃ©e d'une patiente Ã  la maternitÃ©, Ã  partir des donnÃ©es exclusivement recueillies avant l'accouchement. DiffÃ©rentes approches de gestion du dÃ©sÃ©quilibre de classes (classe minoritaire) ont Ã©tÃ© explorÃ©es, notamment :
- RÃ©gression logistique avec diffÃ©rents types de rÃ©Ã©quilibrage (SMOTE, SMOTEENN, SMOTETomek, RandomUnderSampler, surpondÃ©ration de la classe minoritaire).
- Random Forest.
- XGBoost.

## ğŸ“ ModÃ©lisation et ExpÃ©riences

### ğŸ“Œ 1. RÃ©gression Logistique avec gestion du dÃ©sÃ©quilibre (SMOTE et variantes)

**Pourquoi cette approche ?**
- SimplicitÃ© d'interprÃ©tation et rapiditÃ© d'exÃ©cution.
- Gestion efficace du dÃ©sÃ©quilibre via SMOTE et ses variantes.

**Observations :**
- Bon Recall  obtenu (>60%) mais precision insatisfaisante (<10%).
- SMOTEENN a lÃ©gÃ¨rement amÃ©liorÃ© les rÃ©sultats.

### ğŸ“Œ 2. Random Forest

**Pourquoi ce modÃ¨le ?**
- CapacitÃ© Ã  capturer les relations non-linÃ©aires complexes.
- Bonne gestion naturelle des donnÃ©es dÃ©sÃ©quilibrÃ©es avec hyperparamÃ©trage optimisÃ©.

**Observations :**
- DifficultÃ© Ã  atteindre un bon Ã©quilibre prÃ©cision-rappel.
- Recall Ã©levÃ© mais faible precision persistante.

### ğŸ“Œ 3. XGBoost

**Pourquoi cette approche ?**
- PossibilitÃ© de modÃ©liser des interactions complexes entre les variables.
- XGBboost largement adoptÃ© par la communautÃ© scientifique pour ces performances.

**Observations :**
- ModÃ¨le performant en recall mais toujours limitÃ© en prÃ©cision.
- Sous Ã©chantillonnage plus impactant sur le score

## ğŸ“Š SynthÃ¨se des rÃ©sultats actuels

| ModÃ¨le | Recall | PrÃ©cision | Points forts | Limitations |
|--------|--------|-----------|--------------|-------------|
| Logistic Regression (SMOTE) | 69% | ~8% | Bonne interprÃ©tabilitÃ©, rapide | TrÃ¨s faible prÃ©cision |
| Random Forest / XGBoost | ~65% | ~9% | ModÃ¨les robustes | DifficultÃ© Ã  Ã©quilibrer prÃ©cision-recall |

## ğŸ” Conclusion intermÃ©diaire

Les rÃ©sultats montrent une grande difficultÃ© Ã  obtenir simultanÃ©ment une bonne prÃ©cision et un recall Ã©levÃ©, reflÃ©tant la complexitÃ© du problÃ¨me (classe extrÃªmement dÃ©sÃ©quilibrÃ©e). Des pistes d'amÃ©lioration incluent l'identification d'une autre variable cible ou l'utilisation de mÃ©thodes avancÃ©es spÃ©cifiques Ã  l'imbalancing.

## ğŸ¤– Tracking & DÃ©ploiement via Hugging Face

- **MLflow** - [Lien vers MLflow](https://thibautmodrin-mlflow.hf.space/)
- **Application (Streamlit)** - [Lien vers ton application](https://github.com/thibautmodrin/Jedha_Full_Stack_HPP_Prediction/blob/main/03_Streamlit/Demo_Streamlit_HPP_Prediction.mp4)

## ğŸ”„ Suivi Workflow

Le workflow du projet est visualisÃ© via Excalidraw pour une meilleure comprÃ©hension du processus de bout en bout.

- **Diagramme de workflow** - [Voir sur Excalidraw](https://excalidraw.com/#json=umo1-2s4zp6QGrUr61F7n,4DxJQNvO13p6kJnvnuRSeA)


## ğŸ› ï¸ Installation et Utilisation

Cloner le projet depuis GitHub :

```bash
git clone https://github.com/ton-github/prediction-hpp-severe.git
cd prediction-hpp-severe
pip install -r requirements.txt
```

Exemple de prÃ©diction :

```python
import joblib

model = joblib.load('hpp_severe_prediction_model.pkl')
patient_data = [[valeur1, valeur2, ..., valeurN]]
prediction = model.predict(patient_data)
print(prediction)
```

## ğŸ“‚ Structure du projet GitHub

```
.
â”œâ”€â”€ notebooks/          # Carnets Jupyter exploratoires
â”œâ”€â”€ streamlit/          # Application Streamlit (POC)
â”œâ”€â”€ mlflow/             # ExpÃ©riences MLflow
â”œâ”€â”€ data/               # Datasets utilisÃ©s
â”œâ”€â”€ README.md           # Documentation du projet
â””â”€â”€ requirements.txt    # DÃ©pendances Python
```

## ğŸ“š Ressources
- Lien vers le rapport annuel de la maternitÃ© (si disponible)
- DonnÃ©es anonymisÃ©es disponibles [ici](https://github.com/thibautmodrin/Jedha_Full_Stack_HPP_Prediction/tree/main/00_Data)

---

âœ¨ Merci Ã  la maternitÃ© de Bourgogne pour les donnÃ©es fournies et leur collaboration prÃ©cieuse dans ce projet ! ğŸŒŸ

